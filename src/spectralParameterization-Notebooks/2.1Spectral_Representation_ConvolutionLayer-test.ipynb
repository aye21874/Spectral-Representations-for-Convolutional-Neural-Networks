{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474498f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d904c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e20e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f52d26",
   "metadata": {},
   "source": [
    "From https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
    "\n",
    "Given an input tensor of shape batch_shape + [in_height, in_width, in_channels] and a filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels], this op performs the following:\n",
    "\n",
    "Flattens the filter to a 2-D matrix with shape [filter_height * filter_width * in_channels, output_channels].\n",
    "\n",
    "Extracts image patches from the input tensor to form a virtual tensor of shape [batch, out_height, out_width, filter_height * filter_width * in_channels].\n",
    "\n",
    "For each patch, right-multiplies the filter matrix and the image patch vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0deb6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class spectralConv2D(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, filters = 32,kernel_size=(3,3),strides=(1, 1), padding='VALID',activation=tf.nn.relu,input_shape=None):\n",
    "        \n",
    "        # Initialization\n",
    "        super(spectralConv2D, self).__init__()\n",
    "        assert len(kernel_size) > 1 , \"Please input the Kernel Size as a 2D tuple\"\n",
    "        self.strides = strides \n",
    "        self.padding = padding\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Initialize Filters \n",
    "        # Assuming Input_shape is channels_last \n",
    "        kernel_shape = [self.kernel_size[0],self.kernel_size[1],input_shape[3],self.filters]\n",
    "        \n",
    "        self.kernel_real = self.add_weight( shape=kernel_shape,\n",
    "                                            initializer=\"glorot_uniform\",\n",
    "                                            trainable=True)\n",
    "        self.kernel_imag = self.add_weight( shape=kernel_shape,\n",
    "                                            initializer=\"glorot_uniform\",\n",
    "                                            trainable=True)\n",
    "        \n",
    "        self.bias = self.add_weight(shape=(self.filters,), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        print(self.kernel_real)\n",
    "        kernel = tf.complex(self.kernel_real,self.kernel_imag)\n",
    "        \n",
    "        spatial_kernel = tf.signal.ifft2d(kernel)\n",
    "                \n",
    "        spatial_kernel=tf.abs(spatial_kernel)\n",
    "        \n",
    "        convolution_output = tf.nn.convolution(\n",
    "                            inputs,\n",
    "                            spatial_kernel,\n",
    "                            strides=list(self.strides),\n",
    "                            padding=self.padding\n",
    "                        )\n",
    "        \n",
    "        convolution_output = tf.nn.bias_add(convolution_output, self.bias)\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            convolution_output= self.activation(convolution_output)\n",
    "            \n",
    "        return convolution_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb8e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cifar-10-python.tar.gz already exists. Begin extracting...\n",
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10 Dataset\n",
    "from modules.utils import load_data\n",
    "X_train, y_train = load_data(mode='train')\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "\n",
    "X_val = X_train[-num_validation:, :]\n",
    "y_val = y_train[-num_validation:]\n",
    "\n",
    "X_train = X_train[:num_training, :]\n",
    "y_train = y_train[:num_training]\n",
    "\n",
    "# Preprocessing: subtract the mean value across every dimension for training data, and reshape it to be RGB size\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train = X_train.astype(np.float32) - mean_image.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "\n",
    "X_train = X_train.reshape(-1,3,32,32).transpose(0,2,3,1) / 255\n",
    "X_val = X_val.reshape(-1,3,32,32).transpose(0,2,3,1) / 255\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04544653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,ReLU,GlobalAveragePooling2D,Softmax,Flatten,Dense #, , AveragePooling2D, MaxPooling2D,,\n",
    "from tensorflow.keras import Model,Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc466d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(spectralConv2D(32, (3,3),input_shape=X_train.shape[1:]))\n",
    "model.add(spectralConv2D(64, (3,3)))\n",
    "model.add(spectralConv2D(128, (3,3)))\n",
    "model.add(spectralConv2D(94, (3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09e992e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee183f2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "<tf.Variable 'spectral_conv2d/Variable:0' shape=(3, 3, 3, 32) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_1/Variable:0' shape=(3, 3, 32, 64) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_2/Variable:0' shape=(3, 3, 64, 128) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_3/Variable:0' shape=(3, 3, 128, 94) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d/Variable:0' shape=(3, 3, 3, 32) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_1/Variable:0' shape=(3, 3, 32, 64) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_2/Variable:0' shape=(3, 3, 64, 128) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_3/Variable:0' shape=(3, 3, 128, 94) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d/Variable:0' shape=(3, 3, 3, 32) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_1/Variable:0' shape=(3, 3, 32, 64) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_2/Variable:0' shape=(3, 3, 64, 128) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_3/Variable:0' shape=(3, 3, 128, 94) dtype=float32>\n",
      "383/383 [==============================] - ETA: 0s - loss: 2.1148 - accuracy: 0.2385<tf.Variable 'spectral_conv2d/Variable:0' shape=(3, 3, 3, 32) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_1/Variable:0' shape=(3, 3, 32, 64) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_2/Variable:0' shape=(3, 3, 64, 128) dtype=float32>\n",
      "<tf.Variable 'spectral_conv2d_3/Variable:0' shape=(3, 3, 128, 94) dtype=float32>\n",
      "383/383 [==============================] - 53s 30ms/step - loss: 2.1146 - accuracy: 0.2386 - val_loss: 2.0055 - val_accuracy: 0.3130\n",
      "Epoch 2/5\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 1.9706 - accuracy: 0.2973 - val_loss: 1.9832 - val_accuracy: 0.3190\n",
      "Epoch 3/5\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 1.9507 - accuracy: 0.3086 - val_loss: 1.9478 - val_accuracy: 0.3360\n",
      "Epoch 4/5\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 1.9358 - accuracy: 0.3170 - val_loss: 1.9556 - val_accuracy: 0.3130\n",
      "Epoch 5/5\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 1.9352 - accuracy: 0.3178 - val_loss: 2.0002 - val_accuracy: 0.3040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa7009c208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5, \n",
    "          validation_data=(X_val, y_val)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3b38ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "spectral_conv2d (spectralCon (None, 30, 30, 32)        1760      \n",
      "_________________________________________________________________\n",
      "spectral_conv2d_1 (spectralC (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "spectral_conv2d_2 (spectralC (None, 26, 26, 128)       147584    \n",
      "_________________________________________________________________\n",
      "spectral_conv2d_3 (spectralC (None, 24, 24, 94)        216670    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 54144)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               6930560   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 7,334,792\n",
      "Trainable params: 7,334,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d1451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
